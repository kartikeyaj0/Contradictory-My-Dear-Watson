{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T02:02:32.047090Z","iopub.execute_input":"2022-05-02T02:02:32.047823Z","iopub.status.idle":"2022-05-02T02:02:32.073158Z","shell.execute_reply.started":"2022-05-02T02:02:32.047706Z","shell.execute_reply":"2022-05-02T02:02:32.072555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:02:32.101838Z","iopub.execute_input":"2022-05-02T02:02:32.102253Z","iopub.status.idle":"2022-05-02T02:02:43.408567Z","shell.execute_reply.started":"2022-05-02T02:02:32.102223Z","shell.execute_reply":"2022-05-02T02:02:43.407873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/contradictory-my-dear-watson/train.csv\")\ntest_data = pd.read_csv(\"../input/contradictory-my-dear-watson/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:03:54.706141Z","iopub.execute_input":"2022-05-02T02:03:54.706431Z","iopub.status.idle":"2022-05-02T02:03:54.953922Z","shell.execute_reply.started":"2022-05-02T02:03:54.706401Z","shell.execute_reply":"2022-05-02T02:03:54.953028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFAutoModel, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:04:04.804000Z","iopub.execute_input":"2022-05-02T02:04:04.804567Z","iopub.status.idle":"2022-05-02T02:04:06.639702Z","shell.execute_reply.started":"2022-05-02T02:04:04.804533Z","shell.execute_reply":"2022-05-02T02:04:06.638822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:04:06.641254Z","iopub.execute_input":"2022-05-02T02:04:06.641495Z","iopub.status.idle":"2022-05-02T02:04:10.196184Z","shell.execute_reply.started":"2022-05-02T02:04:06.641468Z","shell.execute_reply":"2022-05-02T02:04:10.195263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEQ_LEN=256\ndef xlm_roberta_encode(df, tokenizer):\n    batch_premises = df['premise'].tolist()\n    batch_hypothesis = df['hypothesis'].tolist()\n\n    tokens = tokenizer(batch_premises, batch_hypothesis, max_length = SEQ_LEN,\n                   truncation=True, padding='max_length',\n                   add_special_tokens=True, return_attention_mask=True,\n                   return_token_type_ids=True,\n                   return_tensors='tf')\n    inputs = {\n          'input_ids': tokens['input_ids'], \n          'attention_mask': tokens['attention_mask'],\n          'token_type_ids': tokens['token_type_ids']  }  \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:04:10.197350Z","iopub.execute_input":"2022-05-02T02:04:10.197596Z","iopub.status.idle":"2022-05-02T02:04:10.203700Z","shell.execute_reply.started":"2022-05-02T02:04:10.197569Z","shell.execute_reply":"2022-05-02T02:04:10.202720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input = xlm_roberta_encode(train_data, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:04:10.205547Z","iopub.execute_input":"2022-05-02T02:04:10.205905Z","iopub.status.idle":"2022-05-02T02:04:12.535184Z","shell.execute_reply.started":"2022-05-02T02:04:10.205869Z","shell.execute_reply":"2022-05-02T02:04:12.534578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(train_input['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:04:12.536459Z","iopub.execute_input":"2022-05-02T02:04:12.536861Z","iopub.status.idle":"2022-05-02T02:04:12.547077Z","shell.execute_reply.started":"2022-05-02T02:04:12.536833Z","shell.execute_reply":"2022-05-02T02:04:12.546578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\ndef build_model(): \n   \n    input_ids = tf.keras.Input(shape=(SEQ_LEN,), dtype=tf.int32, name=\"input_ids\")\n    attention_mask = tf.keras.Input(shape=(SEQ_LEN,), dtype=tf.int32, name=\"attention_mask\")\n    token_type_ids = tf.keras.Input(shape=(SEQ_LEN,), \n                                    dtype=tf.int32,  name=\"token_type_ids\")\n        \n    model = AutoModelForMaskedLM.from_pretrained('xlm-roberta-large')\n    embedding = model([input_ids, attention_mask , token_type_ids])[0] \n    inputs=[input_ids, attention_mask  , token_type_ids ] \n    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n        \n    final_model = tf.keras.Model(inputs=inputs, outputs=output)\n    hp_learning_rate = 1e-6\n    final_model.compile(tf.keras.optimizers.Adam(lr = hp_learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])   \n    return final_model ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:06:16.795309Z","iopub.execute_input":"2022-05-02T02:06:16.795771Z","iopub.status.idle":"2022-05-02T02:06:16.804065Z","shell.execute_reply.started":"2022-05-02T02:06:16.795728Z","shell.execute_reply":"2022-05-02T02:06:16.803551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForMaskedLM","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:06:14.028448Z","iopub.execute_input":"2022-05-02T02:06:14.028749Z","iopub.status.idle":"2022-05-02T02:06:14.810522Z","shell.execute_reply.started":"2022-05-02T02:06:14.028717Z","shell.execute_reply":"2022-05-02T02:06:14.809924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope(): \n    xlm_roberta_model = build_model()\n    xlm_roberta_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:06:20.115675Z","iopub.execute_input":"2022-05-02T02:06:20.116344Z","iopub.status.idle":"2022-05-02T02:07:42.111762Z","shell.execute_reply.started":"2022-05-02T02:06:20.116312Z","shell.execute_reply":"2022-05-02T02:07:42.110560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlm_roberta_model.fit(train_input, train_data.label.values, epochs = 5, verbose = 1, batch_size = 30, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:02:43.775671Z","iopub.status.idle":"2022-05-02T02:02:43.775995Z","shell.execute_reply.started":"2022-05-02T02:02:43.775824Z","shell.execute_reply":"2022-05-02T02:02:43.775841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input = xlm_roberta_encode(test_data, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:02:43.777645Z","iopub.status.idle":"2022-05-02T02:02:43.777955Z","shell.execute_reply.started":"2022-05-02T02:02:43.777796Z","shell.execute_reply":"2022-05-02T02:02:43.777812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [np.argmax(i) for i in xlm_roberta_model.predict(test_input)]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:02:43.779027Z","iopub.status.idle":"2022-05-02T02:02:43.779331Z","shell.execute_reply.started":"2022-05-02T02:02:43.779174Z","shell.execute_reply":"2022-05-02T02:02:43.779189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_data.id.copy().to_frame()\nsubmission['prediction'] = predictions\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:02:43.780112Z","iopub.status.idle":"2022-05-02T02:02:43.780415Z","shell.execute_reply.started":"2022-05-02T02:02:43.780249Z","shell.execute_reply":"2022-05-02T02:02:43.780264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:02:43.782211Z","iopub.status.idle":"2022-05-02T02:02:43.782806Z","shell.execute_reply.started":"2022-05-02T02:02:43.782615Z","shell.execute_reply":"2022-05-02T02:02:43.782643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}